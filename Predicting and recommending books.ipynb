{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install surprise\n",
    "!pip install gradio\n",
    "!pip install BeautifulSoup4\n",
    "!pip install requests\n",
    "\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import gradio as gr\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(23)\n",
    "np.random.seed(23)\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(filename='myapp.log', level=logging.CRITICAL)\n",
    "logger.info('Started')\n",
    "\n",
    "#Abrimos el recién descargado\n",
    "file_path = 'dataset_goodreads_with_sentiment.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "#Miramos las primeras filas\n",
    "print(df.head())\n",
    "\n",
    "#Filtrar usuarios y libros con pocos ratings\n",
    "min_ratings_user = 5  # Ajusta el umbral según necesidad\n",
    "min_ratings_book = 5\n",
    "\n",
    "# Filtrar libros con al menos min_ratings_book ratings\n",
    "filtered_books = df.groupby('book_id').filter(lambda x: len(x) >= min_ratings_book)\n",
    "\n",
    "# Filtrar usuarios con al menos min_ratings_user ratings\n",
    "filtered_df = filtered_books.groupby('user_id').filter(lambda x: len(x) >= min_ratings_user)\n",
    "\n",
    "# Paso 3: Definir el lector para surprise (formato de los datos)\n",
    "reader = Reader(rating_scale=(1, 5))  # Define la escala de calificaciones de 1 a 5\n",
    "\n",
    "# Paso 4: Convertir los datos de pandas a surprise dataset\n",
    "data = Dataset.load_from_df(filtered_df[['user_id', 'book_id', 'rating']], reader)\n",
    "\n",
    "# Paso 5: Dividir los datos en conjunto de entrenamiento y prueba\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=23)\n",
    "\n",
    "# Paso 6: Crear el modelo KNN utilizando la métrica cosine\n",
    "sim_options = {'name': 'pearson', 'user_based': False}  # 'user_based': True si quieres similitud entre usuarios\n",
    "knn = KNNBasic(k=20, sim_options=sim_options)\n",
    "\n",
    "# Paso 7: Entrenar el modelo\n",
    "knn.fit(trainset)\n",
    "\n",
    "# Paso 8: Predecir en el conjunto de prueba\n",
    "predictions = knn.test(testset)\n",
    "\n",
    "# Paso 9: Evaluar la precisión del modelo\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "# Mapeo de los nombres a los user_id en el dataset\n",
    "name_user_id = {\n",
    "    'Maria': '000a1016fda6008d1edbba720ca00851',  # ID correspondiente a Maria\n",
    "    'Peter': 'ba68089466d16e33ff2f18d375511b17',  # ID correspondiente a Peter\n",
    "    'Adam': '0011e1a9112b3d798702ef5b20bbf35b',   # ID correspondiente a Adam\n",
    "    'Andrea': '000efb30c5236d7437c3cdf4bf3e4dc7',  # ID correspondiente a Andrea\n",
    "    'Lucrecia': '0019de4561419b7543238e0979f2f33e' # ID correspondiente a Lucrecia\n",
    "}  \n",
    "\n",
    "def resolve_title_author(book_id):\n",
    "    # URL de la página que quieres hacer scraping\n",
    "\n",
    "    url = 'https://www.goodreads.com/book/show/'+str(book_id)  # Reemplaza con la URL real\n",
    "\n",
    "    # Obtener el contenido de la página web\n",
    "    response = requests.get(url)\n",
    "    book_title=\"\"\n",
    "    author_name=\"\"\n",
    "    # Verificar que la petición fue exitosa\n",
    "    if response.status_code == 200:\n",
    "        # Parsear el contenido HTML\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Buscar el elemento con el atributo data-testid=\"bookTitle\"\n",
    "        book_title_element = soup.find(attrs={\"data-testid\": \"bookTitle\"})\n",
    "        metadata_section = soup.find(class_='BookPageMetadataSection')\n",
    "\n",
    "        # Obtener el texto dentro del elemento\n",
    "        if book_title_element:\n",
    "            book_title = book_title_element.get_text()\n",
    "            logger.info(f\"El título del libro es: {book_title}\")\n",
    "        else:\n",
    "            logger.info(\"No se encontró el elemento con data-testid='bookTitle'\")\n",
    "            \n",
    "            \n",
    "        if metadata_section:\n",
    "        # Buscar el span que tiene 'class=\"ContributorLink__name\"' y 'data-testid=\"name\"'\n",
    "            contributor_name = metadata_section.find('span', attrs={\"class\": \"ContributorLink__name\", \"data-testid\": \"name\"})\n",
    "\n",
    "            # Obtener el texto del elemento\n",
    "            if contributor_name:\n",
    "                author_name = contributor_name.get_text()\n",
    "                logger.info(f\"Nombre del autor: {author_name}\")\n",
    "            else:\n",
    "                logger.info(\"No se encontró el 'span' con class='ContributorLink__name' y data-testid='name'\")\n",
    "        else:\n",
    "            logger.info(\"No se encontró la sección 'BookPageMetadataSection'\")\n",
    "        \n",
    "    else:\n",
    "        logger.info(f\"Error al acceder a la página, código de estado: {response.status_code}\")\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    return book_title, author_name\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "def predict_books_for_id(user_id):\n",
    "   # Obtener todos los libros (ítems) únicos del DataFrame filtrado\n",
    "    all_books = filtered_df['book_id'].unique()\n",
    "\n",
    "    # Obtener los libros que el usuario ha calificado en el conjunto de entrenamiento\n",
    "    user_rated_books = [r[0] for r in trainset.ur[trainset.to_inner_uid(user_id)]]\n",
    "\n",
    "    # Identificar los libros no leídos\n",
    "    unread_books = [book for book in all_books if book not in user_rated_books]\n",
    "\n",
    "    recommended_books = []\n",
    "    # Predecir la calificación para cada libro no leído\n",
    "    for book_id in unread_books:\n",
    "        prediccion = knn.predict(user_id, book_id)\n",
    "        recommended_books.append((book_id, prediccion.est))\n",
    "\n",
    "    # Ordenar los libros por el rating predicho en orden descendente\n",
    "    recommended_books = sorted(recommended_books, key=lambda x: x[1], reverse=True)\n",
    "    return recommended_books\n",
    "\n",
    "def recommend_books(name, number_books):\n",
    "    name_user_id = {\n",
    "        'Maria': '000a1016fda6008d1edbba720ca00851',\n",
    "        'Peter': 'ba68089466d16e33ff2f18d375511b17',\n",
    "        'Adam': '0011e1a9112b3d798702ef5b20bbf35b',\n",
    "        'Andrea': '000efb30c5236d7437c3cdf4bf3e4dc7',\n",
    "        'Lucrecia': '0019de4561419b7543238e0979f2f33e'\n",
    "    }\n",
    "    \n",
    "    user_id = name_user_id[name]\n",
    "    top_n = int(number_books)\n",
    "    recommended_books = predict_books_for_id(user_id)\n",
    "    \n",
    "    final_text = f\"Recommended books for {name}:\\n\"\n",
    "    for book_id, pred_rating in recommended_books[:top_n]:\n",
    "        #final_text = final_text + f\"Libro ID: {book_id}, Rating Predicho: {pred_rating}\\n\"\n",
    "        book_title, author_name = resolve_title_author(book_id)\n",
    "        final_text = final_text + f\"Book: {book_title}, Author: {author_name}, Rating: {pred_rating}\\n\"\n",
    "        \n",
    "    return final_text\n",
    "\n",
    "# Create a Gradio interface for the function\n",
    "demo = gr.Interface(fn=recommend_books, inputs=[\"text\", \"text\"], outputs=\"text\")\n",
    "\n",
    "# When the user hits 'Flag' Button, your application will persist the value into a file. \n",
    "\n",
    "# Launch the interface\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
